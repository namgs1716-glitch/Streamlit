import streamlit as st
import google.generativeai as genai
import rag  # ë°©ê¸ˆ ë§Œë“  rag.pyë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="CSI ì•ˆì „ê´€ë¦¬ ì±—ë´‡", page_icon="ğŸ—ï¸")
st.title("ğŸ—ï¸ ê±´ì„¤ê³µì‚¬ ì•ˆì „ê´€ë¦¬ ì¢…í•©ì •ë³´ë§(CSI)")
st.caption("AI ì§€ëŠ¥í˜• ë„ìš°ë¯¸ (RAG ê¸°ë°˜)")

# --- 2. API í‚¤ ì…ë ¥ ---
with st.sidebar:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.text_input("Google API Key", type="password")
    
    st.markdown("---")
    st.write("ğŸ“‹ **ë°ì´í„° ë¡œë“œ ìƒíƒœ**")
    
    # API í‚¤ê°€ ìˆì„ ë•Œë§Œ ë°ì´í„° ë¡œë“œ ì‹œë„
    vectorstore = None
    if api_key:
        try:
            with st.spinner("ì§€ì‹ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                vectorstore = rag.get_vectorstore(api_key)
            st.success("âœ… ì§€ì‹ ë°ì´í„° ì¥ì°© ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- 3. ëŒ€í™” UI ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. ê±´ì„¤ê³µì‚¬ ì•ˆì „ê´€ë¦¬ ì¢…í•©ì •ë³´ë§ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì‹­ì‹œì˜¤."}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    if not api_key:
        st.error("API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
    st.chat_message("user").write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ê´€ë ¨ ê·œì •ì„ ì°¾ì•„ë³´ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                # 1) RAG ëª¨ë“ˆì„ í†µí•´ ì—‘ì…€ì—ì„œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰
                context_data = rag.query_rag(vectorstore, prompt)
                
                # 2) Geminiì—ê²Œ ê²€ìƒ‰ ê²°ê³¼ + ì§ˆë¬¸ì„ ê°™ì´ ì¤Œ
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                
                full_prompt = f"""
                ë‹¹ì‹ ì€ ê±´ì„¤ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ê²€ìƒ‰ëœ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤.
                ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ê³ , ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤.
                ë‹µë³€ì€ 'í•˜ì‹­ì‹œì˜¤'ì²´ë¥¼ ì‚¬ìš©í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

                [ê²€ìƒ‰ëœ ì •ë³´]
                {context_data}

                [ì‚¬ìš©ì ì§ˆë¬¸]
                {prompt}
                """
                
                response = model.generate_content(full_prompt)
                
                # 3) ê²°ê³¼ ì¶œë ¥
                st.write(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
                # (ì˜µì…˜) ë””ë²„ê¹…ìš©: ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ì ‘ëŠ” ë©”ë‰´ë¡œ ë³´ì—¬ì¤Œ
                with st.expander("ì°¸ê³ í•œ ë¬¸ì„œ ì›ë¬¸ ë³´ê¸°"):
                    st.text(context_data)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")